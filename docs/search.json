[{"path":"https://r-topics.org/articles/extended_installation_guide.html","id":"rjava-installation","dir":"Articles","previous_headings":"","what":"rJava installation","title":"Extended Installation Guide","text":"Please visit https://www.java.com information installing JAVA.","code":""},{"path":"https://r-topics.org/articles/topics.html","id":"usage","dir":"Articles","previous_headings":"","what":"Usage","title":"Getting started","text":"example topics used predict PHQ-9 score, pipeline can run follows: 1. Data Preprocessing preprocess data, run following command:  2. Model Training train LDA model, run following command: 3. Model Inference infer topic term distribution documents, run following command: 4. Statistical Analysis analyze relationship topics prediction variable, run following command: 5. Visualization visualize significant topics wordclouds, run following command:","code":"library(topics) #>  #> This is topics: your text's new best friend (version 0.40.2). #> Please note that the topics package requires you to download and install java from www.java.com.  #>  #> For more information about the topics package see www.r-topics.org and www.r-text.org.  dtm <- topicsDtm(   data = dep_wor_data$Depword)  # Check the results from the dtm and refine stopwords and removal rates if necessary dtm_evaluation <- topicsDtmEval(   dtm) dtm_evaluation$frequency_plot model <- topicsModel(   dtm = dtm,   num_topics = 20,   num_iterations = 1000) preds <- topicsPreds(   model = model,   data = dep_wor_data$Depword) test <- topicsTest(   data = dep_wor_data,   model = model,   preds = preds,   x_variable = \"PHQ9tot\",   controls = c(\"Age\"),   test_method = \"linear_regression\") plot_list <- topicsPlot(   model = model,   test = test,   figure_format = \"png\")  # showing some of the plots plot_list$square1 #> $t_5"},{"path":"https://r-topics.org/articles/topics.html","id":"articles-using-the-topics-package","dir":"Articles","previous_headings":"Usage","what":"Articles using the topics-package","title":"Getting started","text":"Differentiating balance harmony natural language analysis: cross-national exploration two understudied wellbeing-related concepts","code":""},{"path":"https://r-topics.org/articles/topics.html","id":"other-relevant-references","dir":"Articles","previous_headings":"Usage","what":"Other relevant references","title":"Getting started","text":"list consists papers analyzing human language similar fashion possible topics. Methods Articles Gaining insights social media language: Methodologies challenges..Kern et al., (2016). Psychological Methods. Computer Science: Python Software DLATK: Differential language analysis toolkit. Schwartz, H. ., Giorgi, et al., (2017). Proceedings 2017 Conference Empirical Methods Natural Language Processing: System Demonstrations DLATK","code":""},{"path":"https://r-topics.org/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Leon Ackermann. Author. Zhuojun Gu. Author. Oscar Kjell. Author, maintainer.","code":""},{"path":"https://r-topics.org/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ackermann L, Gu Z, Kjell O (2024). “R-package visualizing text topics.” doi:10.5281/zenodo.11165378, https://github.com/theharmonylab/topics.","code":"@Misc{,   title = {An R-package for visualizing text in topics.},   author = {Leon Ackermann and Zhuojun Gu and Oscar Kjell},   doi = {10.5281/zenodo.11165378},   year = {2024},   url = {https://github.com/theharmonylab/topics}, }"},{"path":"https://r-topics.org/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"topics","text":"topics package uses JAVA, another programming language. Please start downloading installing www.java.com/en/download/. open R run:","code":"install.packages(\"devtools\") devtools::install_github(\"theharmonylab/topics\")  # if you run in to any installation problem, try installing rJava first.  # Before open the library, consider setting this option (can increase 5000);  without it the code may ran out of memory options(java.parameters = \"-Xmx5000m\")"},{"path":"https://r-topics.org/index.html","id":"table-of-contents","dir":"","previous_headings":"","what":"Table of Contents","title":"topics","text":"Overview Installation Usage","code":""},{"path":"https://r-topics.org/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"topics","text":"pipeline composed following steps: 1. Data Preprocessing data preprocessing converts data document term matrix (DTM) removes stopwords, punctuation, etc. data format needed LDA model. 2. Model Training model training step trains LDA model DTM number iterations predefined amount topics. 3. Model Inference model inference step uses trained LDA model infer topic term distribution documents. 4. Statistical Analysis analysis includes methods like linear regression, binary regression, ridge regression correlation analyze relationship topics prediction variable. possible control number variables adjust p-value multiple comparisons. 5. Visualization visualization step creates wordclouds significant topics found statistical analysis.","code":""},{"path":"https://r-topics.org/reference/dep_wor_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Example data about mental health descirptions . — dep_wor_data","title":"Example data about mental health descirptions . — dep_wor_data","text":"Example data mental health descirptions .","code":""},{"path":"https://r-topics.org/reference/dep_wor_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example data about mental health descirptions . — dep_wor_data","text":"","code":"dep_wor_data"},{"path":"https://r-topics.org/reference/dep_wor_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example data about mental health descirptions . — dep_wor_data","text":"data frame 500 participants 13 variables: Depselect Words respondents selected pre-defined list Worselect Words respondents selected pre-defined list Depword Wrods respondents describe experience depression life Worword Words respondents describe experience depression life Depphrase phrases respondents describe experience depression life Worphrase Phrases respondents describe experience anxiety life Deptext Text respondents describe experience depression life Wortext Text respondents describe experience anxiety life Gender Respondents gender 0=male, 1=female Age respondents age years PHQ9tot total score respondents PHQ-9 GAD7tot total score respondents GAD-7","code":""},{"path":"https://r-topics.org/reference/dep_wor_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example data about mental health descirptions . — dep_wor_data","text":"<https://osf.io/preprints/psyarxiv/p67db>","code":""},{"path":"https://r-topics.org/reference/topicsDtm.html","id":null,"dir":"Reference","previous_headings":"","what":"Document Term Matrix — topicsDtm","title":"Document Term Matrix — topicsDtm","text":"function creates document term matrix","code":""},{"path":"https://r-topics.org/reference/topicsDtm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Document Term Matrix — topicsDtm","text":"","code":"topicsDtm(   data,   ngram_window = c(1, 3),   stopwords = stopwords::stopwords(\"en\", source = \"snowball\"),   removalword = \"\",   pmi_threshold = NULL,   occurance_rate = 0,   removal_mode = \"none\",   removal_rate_most = 0,   removal_rate_least = 0,   shuffle = TRUE,   seed = 42L,   threads = 1 )"},{"path":"https://r-topics.org/reference/topicsDtm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Document Term Matrix — topicsDtm","text":"data (list) list containing text data entry belonging unique id ngram_window (list) minimum maximum n-gram length, e.g., c(1,3) stopwords (stopwords) stopwords remove, e.g., stopwords::stopwords(\"en\", source = \"snowball\") removalword (string) word remove pmi_threshold (integer; experimental) Pointwise Mutual Information (PMI) measures association terms comparing co-occurrence probability individual probabilities, highlighting term pairs occur together often expected chance; implementation, terms average PMI specified threshold (pmi_threshold) removed document-term matrix. occurance_rate (integer) rate occurence word removed removal_mode (string) Mode removal -> one c(\"none\", \"frequency\", \"term\", \"percentage\"). frequency removes words certain frequency certain frequency, indicated removal_rate_least removal_rate_most. term removes absolute number terms frequent least frequent. percentage removes number terms indicated removal_rate_least removal_rate_most relative number terms matrix removal_rate_most (integer) rate frequent words removed, functionality depends removal_mode removal_rate_least (integer) rate least frequent words removed, functionality depends removal_mode shuffle (boolean) Shuffle data analyses seed (integer) seed set reproducibility threads (integer) number threads use; also called cpu (CreateDtm).","code":""},{"path":"https://r-topics.org/reference/topicsDtm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Document Term Matrix — topicsDtm","text":"document term matrix","code":""},{"path":"https://r-topics.org/reference/topicsDtm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Document Term Matrix — topicsDtm","text":"","code":"# \\donttest{  # Create a Dtm and remove the terms that occur less than 4 times and more than 500 times.  dtm <- topicsDtm(data = dep_wor_data$Depphrase,                  removal_mode = \"frequency\",                  removal_rate_least = 4,                  removal_rate_most = 500)  # Create Dtm and remove the 1 least and 1 most frequent terms. dtm <- topicsDtm(data = dep_wor_data$Depphrase,                  removal_mode = \"term\",                  removal_rate_least = 1,                  removal_rate_most = 1)  # Create Dtm and remove the 1% least frequent and 1% most frequent terms. dtm <- topicsDtm(data = dep_wor_data$Depphrase,                  removal_mode = \"percentage\",                  removal_rate_least = 1,                  removal_rate_most = 1)  # }"},{"path":"https://r-topics.org/reference/topicsDtmEval.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize and Visualize your Document Term Matrix — topicsDtmEval","title":"Summarize and Visualize your Document Term Matrix — topicsDtmEval","text":"function creates frequency table DTM generates four plots visualization","code":""},{"path":"https://r-topics.org/reference/topicsDtmEval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize and Visualize your Document Term Matrix — topicsDtmEval","text":"","code":"topicsDtmEval(dtm)"},{"path":"https://r-topics.org/reference/topicsDtmEval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize and Visualize your Document Term Matrix — topicsDtmEval","text":"dtm (R_obj) document term matrix -> output topicsDtm function","code":""},{"path":"https://r-topics.org/reference/topicsDtmEval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize and Visualize your Document Term Matrix — topicsDtmEval","text":"named list containing: dtm_summary dataframe terms frequencies. frequency_plot bar plot term frequencies example terms. frequency_plot_30_least bar plot 30 least frequent terms (numer terms > 30). frequency_plot_30_most bar plot 30 frequent terms (numer terms > 30). histogram_of_frequencies histogram term frequencies (information   frequency_plot presented differently).","code":""},{"path":"https://r-topics.org/reference/topicsGrams.html","id":null,"dir":"Reference","previous_headings":"","what":"N-grams — topicsGrams","title":"N-grams — topicsGrams","text":"function computes ngrams text","code":""},{"path":"https://r-topics.org/reference/topicsGrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"N-grams — topicsGrams","text":"","code":"topicsGrams(   data,   ngram_window = c(1, 3),   stopwords = stopwords::stopwords(\"en\", source = \"snowball\"),   pmi_threshold = 0,   top_frequent = 200 )"},{"path":"https://r-topics.org/reference/topicsGrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"N-grams — topicsGrams","text":"data (tibble) data ngram_window (list) minimum maximum n-gram length, e.g. c(1,3) stopwords (stopwords) stopwords remove, e.g. stopwords::stopwords(\"en\", source = \"snowball\") pmi_threshold (integer) pmi threshold, shall used set 0 top_frequent (integer) number frequently occuring ngrams included output.","code":""},{"path":"https://r-topics.org/reference/topicsGrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"N-grams — topicsGrams","text":"list containing tibble ngrams frequency probability tibble containing relative frequency ngrams user","code":""},{"path":"https://r-topics.org/reference/topicsModel.html","id":null,"dir":"Reference","previous_headings":"","what":"Topic modelling — topicsModel","title":"Topic modelling — topicsModel","text":"function create train LDA model.","code":""},{"path":"https://r-topics.org/reference/topicsModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Topic modelling — topicsModel","text":"","code":"topicsModel(   dtm,   num_topics = 20,   num_top_words = 10,   num_iterations = 1000,   seed = 42 )"},{"path":"https://r-topics.org/reference/topicsModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Topic modelling — topicsModel","text":"dtm (R_obj) document term matrix -> output topicsDtm function num_topics (integer) number topics created num_top_words (integer) number top words displayed num_iterations (integer) number iterations run model seed (integer) seed set reproducibility","code":""},{"path":"https://r-topics.org/reference/topicsModel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Topic modelling — topicsModel","text":"named list containing following elements: name Description instances Java object reference: list documents used topic modeling,   document preprocessed (e.g., tokenized vectorized). object part   Mallet package's internal structure. inferencer Java object reference: topic inferencer, allows inference   topic distributions new, unseen documents based trained model. top_terms_mallet data frame containing top terms topic, showing concepts    topic likely represents. number top terms shown can adjusted argument     num_top_words. top_terms data frame containing top terms topic, showing concepts   topic likely represents. number top terms shown can adjusted argument   num_top_words. phi matrix topic-word distribution: row represents topic, column   represents word document term matrix. values show probability word given   topic P(word|topic). topic_docs matrix document-topic distribution: row represents document,   column represents topic. values show probability topic given document, P(topic|document). frequencies data frame term frequencies. word = every word document term matrix,   word.freq = frequency word across documents, doc.freq = number documents word appears. vocabulary character vector unique terms document term matrix. labels list topic labels. short labels representative term topic,   making easy identify understand . theta data frame document-topic probabilities: row represents document, column    represents topic. Similar topic_docs, shows contribution topic document.    row sums 1, representing document’s composition topics. prevalence numeric vector showing overall prevalence (prominence) topic corpus.    prevalences expressed percentages relative topics  add 100    Higher values indicate topics present documents. coherence numeric vector showing coherence topic. Coherence scores indicate    semantically consistent interpretable topics . Higher coherence generally indicates    better-quality topics. pred_model list containing components predictive model, including phi    (word-topic probability matrix), theta (document-topic probabilities matrix), alpha (Dirichlet prior topics),    gamma (hyperparameters word-topic assignments), data (sparse matrix representing document term matrix.) dtm_settings list settings used preprocessing building document term matrix (dtm),   including n-gram ranges, stopword removal, frequency thresholds, random seed settings. summary summary data frame comprising topic numbers, labels, coherence scores, prevalence scores, top terms.","code":""},{"path":"https://r-topics.org/reference/topicsModel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Topic modelling — topicsModel","text":"","code":"# \\donttest{ # Create LDA Topic Model  save_dir_temp <- tempfile() dtm <- topicsDtm(data = dep_wor_data$Depphrase)  model <- topicsModel( dtm = dtm, # output of topicsDtm() num_topics = 20, num_top_words = 10, num_iterations = 1000, seed = 42) # }"},{"path":"https://r-topics.org/reference/topicsPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot word clouds — topicsPlot","title":"Plot word clouds — topicsPlot","text":"function create word clouds topic figures","code":""},{"path":"https://r-topics.org/reference/topicsPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot word clouds — topicsPlot","text":"","code":"topicsPlot(   model = NULL,   ngrams = NULL,   test = NULL,   p_alpha = 0.05,   p_adjust_method = \"none\",   ngrams_max = 30,   ngram_select = \"prevalence\",   color_scheme = \"default\",   highlight_topic_words = c(not = \"#2d00ff\", never = \"#2d00ff\"),   scale_size = FALSE,   plot_topics_idx = NULL,   allowed_word_overlap = NULL,   plot_n_most_prevalent_topics = NULL,   save_dir = NULL,   figure_format = \"svg\",   width = 6,   height = 5,   max_size = 10,   seed = 42,   scatter_legend_dot_size = 15,   scatter_legend_bg_dot_size = 9,   scatter_legend_n = c(1, 1, 1, 1, 0, 1, 1, 1, 1),   scatter_legend_method = c(\"mean\"),   scatter_legend_specified_topics = NULL,   scatter_legend_topic_n = FALSE,   scatter_show_axis_values = TRUE,   grid_legend_title = \"legend_title\",   grid_legend_title_size = 5,   grid_legend_title_color = \"black\",   grid_legend_x_axes_label = \"legend_x_axes_label\",   grid_legend_y_axes_label = \"legend_y_axes_label\",   grid_legend_number_color = \"black\",   grid_legend_number_size = 5 )"},{"path":"https://r-topics.org/reference/topicsPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot word clouds — topicsPlot","text":"model (list) trained topics model, e.g., topicsModel(). NULL plotting ngrams. ngrams (list) output topicsGram() function. NULL plotting topics. Note 1: possible plot tags like <place>; < replaced underscore. Note 2: possible plot dash - alone, replaced `_-_`. test (list) test results; plotting according dimension(s) include object topicsTest() function. p_alpha (integer) p-value threshold use significance testing. p_adjust_method (character) Method adjust/correct p-values multiple comparisons (default = \"none\"; see also \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\", \"fdr\"). ngrams_max (integer) maximum number n-grams plot. ngram_select (character) Method select ngrams_max, using ngram test use \"prevalence\" \"estimate\"; use ngrams use \"pmi\", \"frequency\", \"proportion\". color_scheme (string 'default' vector) color scheme. plots including test, color_scheme clude 2 colours (1 gradient pair), : c(\"lightgray\", \"darkblue) 1 dimensional plots n-grams contain 4 colours (2 gradient pairs), : c( \"#EAEAEA\", \"darkred\", # negative ngrams colors \"#EAEAEA\", \"darkgreen\" # positve ngrams colors) 1-dimension plots topics, contain 6 colours (3 gradient pairs), c( \"#EAEAEA\", \"darkred\",     # negative topics colors \"#EAEAEA\", \"darkgray\",     # colours topics significantly associated \"#EAEAEA\", \"darkgreen\"     # positve topics colors) 2-dimensional plots topics, color scheme contain 18 colours (9 gradient pairs), : c(   \"lightgray\", \"#398CF9\",     # quadrant 1 (upper left corner) \"lightgray\", \"#60A1F7\",     # quadrant 2 \"lightgray\", \"#5dc688\",     # quadrant 3 (upper right corner) \"lightgray\", \"#e07f6a\",     # quadrant 4 \"lightgray\", \"darkgray\",     # quadrant 5 (middle square) \"lightgray\", \"#40DD52\",     # quadrant 6 \"lightgray\", \"#FF0000\",     # quadrant 7 (bottom left corner) \"lightgray\", \"#EA7467\",     # quadrant 8 \"lightgray\", \"#85DB8E\")     # quadrant 9 (bottom right corner). highlight_topic_words (named vector) Words highlight topics (e.g., negative words). values vector determine color: highlight_topic_words = c(= \"#2d00ff\", never = \"#2d00ff\"); note needs hexa codes, color naming \"blue\" work. scale_size (logical) Whether scale size words. plot_topics_idx (vector)  index indices topics plot (look model-object indices). can, example, c(1, 3:5) plot topic t_1, t_3, t_4 t_5) (optional). allowed_word_overlap (numeric) filter function determining maximum number identical words topics plotted. filter removes topics within \"color group\" also include removing topics distribution grid legends; (Note adjustment multiple comparison taking place removed; .e., adjusted p-values affected filter). plot_n_most_prevalent_topics (numeric) Plots n prevalent topics given model. save_dir (string) directory save plots. figure_format (string) Set figure format, e.g., \".svg\", \".png\". width (integer) width topic (units = \"\"). height (integer) width topic (units = \"\"). max_size (integer) maximum size words. seed (integer) seed set reproducibility. scatter_legend_dot_size (integer) size dots scatter legend. scatter_legend_bg_dot_size (integer) size background dots scatter legend. scatter_legend_n (numeric vector) vector determining number dots emphasize quadrant scatter legend. example: c(1,1,1,1,0,1,1,1,1) result one dot quadrant except middle quadrant. scatter_legend_method (string) method filter topics emphasized scatter legend; either \"mean\", \"max_x\", \"max_y\". scatter_legend_specified_topics (vector) Specify topic(s) emphasize scatter legend. example, c(\"t_1\", \"t_2\"). set, scatter_legend_method effect. scatter_legend_topic_n (boolean) TRUE, topic numbers shown scatter legend. scatter_show_axis_values (boolean) TRUE, estimate values shown distribution plot axes. grid_legend_title Title grid topic plot. grid_legend_title_size Title size grid topic plot. grid_legend_title_color Legend title color grid topic plot. grid_legend_x_axes_label x-axis label grid topic plot. grid_legend_y_axes_label y-axis label grid topic plot. grid_legend_number_color Text color legend boxes grid topic plot. grid_legend_number_size Text size legend boxes.","code":""},{"path":"https://r-topics.org/reference/topicsPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot word clouds — topicsPlot","text":"function provides list topic plots (significant topics), legend plot, plot showing topic distribution. save_dir specified, saves plots directory. want show plots irrespective topics' significance, set p_alpha = 1.","code":""},{"path":"https://r-topics.org/reference/topicsPreds.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict topic distributions — topicsPreds","title":"Predict topic distributions — topicsPreds","text":"function predict topics new document trained model.","code":""},{"path":"https://r-topics.org/reference/topicsPreds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict topic distributions — topicsPreds","text":"","code":"topicsPreds(   model,   data,   num_iterations = 200,   sampling_interval = 10,   burn_in = 10,   seed = 42,   create_new_dtm = FALSE )"},{"path":"https://r-topics.org/reference/topicsPreds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict topic distributions — topicsPreds","text":"model (list) trained model. data (tibble) text variable want infer topic distribution. can data used create dtm new data. num_iterations (integer) number iterations run model. sampling_interval number iterations consecutive samples collected. Gibbs Sampling process. technique, known thinning, helps reduce correlation consecutive samples improves quality final estimates ensuring independent. Purpose: specifying sampling_interval, avoid collecting highly correlated samples, can lead robust accurate topic distributions. Example: sampling_interval = 10, algorithm collects sample every 10 iterations (e.g., iteration 10, 20, 30, etc.). Typical Values: Default: 10; Range: 5 50 (depending complexity size data). burn_in number initial iterations discarded Gibbs Sampling process. early iterations may representative final sampling distribution model still stabilizing. Purpose: burn_in period allows model converge stable state collecting samples, improving quality inferred topic distributions. Example: burn_in = 50, first 50 iterations Gibbs Sampling process discarded, sampling begins afterward. Typical Values: Default: 50 100 Range: 10 1000 (larger datasets complex models may require longer burn-period). seed (integer) seed set reproducibility. create_new_dtm (boolean) applying model new data (used training), can help make new dtm. Currently experimental, using textmineR::CreateDtm() function rather topicsDtm() function, functions.","code":""},{"path":"https://r-topics.org/reference/topicsPreds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict topic distributions — topicsPreds","text":"tibble predictions: rows represent documents, columns represent topics. values cells indicate proportion topic within corresponding document.","code":""},{"path":"https://r-topics.org/reference/topicsPreds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict topic distributions — topicsPreds","text":"","code":"# \\donttest{ # Predict topics for new data with the trained model  dtm <- topicsDtm( data = dep_wor_data$Depphrase)  model <- topicsModel(dtm = dtm, # output of topicsDtm()                      num_topics = 20,                      num_top_words = 10,                      num_iterations = 1000,                      seed = 42)                       preds <- topicsPreds(model = model, # output of topicsModel()                      data = dep_wor_data$Depphrase) # }"},{"path":"https://r-topics.org/reference/topicsTest.html","id":null,"dir":"Reference","previous_headings":"","what":"Test topics or n-grams — topicsTest","title":"Test topics or n-grams — topicsTest","text":"Statistically test topics n-grams relation one two variables using regression t-test.","code":""},{"path":"https://r-topics.org/reference/topicsTest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test topics or n-grams — topicsTest","text":"","code":"topicsTest(   data,   model = NULL,   preds = NULL,   ngrams = NULL,   x_variable = NULL,   y_variable = NULL,   controls = c(),   test_method = \"default\",   p_adjust_method = \"fdr\",   seed = 42 )"},{"path":"https://r-topics.org/reference/topicsTest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test topics or n-grams — topicsTest","text":"data (tibble) tibble containing variables tested. model (list) trained model LDA-model topicsModel() function. preds (tibble) predictions topicsPred() function. ngrams (list) Output n-gram function. x_variable (string) x variable name predicted, plotted (needed regression correlation). y_variable (string) y variable name predicted, plotted (needed regression correlation). controls (vector) control variables (supported yet). test_method (string) test method use. \"default\" checks x_variable y_variable contain 0s 1s, applies logistic regression; otherwise applies linear regression. Alternatively, user may manually specify either \"linear_regression\" \"logistic_regression\". p_adjust_method (character) Method adjust/correct p-values multiple comparisons (default = \"fdr\"; see also \"holm\", \"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"\",  \"none\"). seed (integer) seed set reproducibility","code":""},{"path":"https://r-topics.org/reference/topicsTest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test topics or n-grams — topicsTest","text":"list test results, test method, prediction variable.","code":""},{"path":"https://r-topics.org/reference/topicsTest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test topics or n-grams — topicsTest","text":"","code":"# \\donttest{ # Test the topic document distribution in respect to a variable  dtm <- topicsDtm(   data = dep_wor_data$Depphrase)  model <- topicsModel(   dtm = dtm, # output of topicsDtm()   num_topics = 20,   num_top_words = 10,   num_iterations = 1000,   seed = 42)                       preds <- topicsPreds(  model = model, # output of topicsModel()  data = dep_wor_data$Depphrase)                       test <- topicsTest(   model = model, # output of topicsModel()   data=dep_wor_data,   preds = preds, # output of topicsPreds()   test_method = \"linear_regression\",   x_variable = \"Age\") #> 1: fitting model formula: z_Age ~ z_t_1 #>  #> 2: fitting model formula: z_Age ~ z_t_2 #>  #> 3: fitting model formula: z_Age ~ z_t_3 #>  #> 4: fitting model formula: z_Age ~ z_t_4 #>  #> 5: fitting model formula: z_Age ~ z_t_5 #>  #> 6: fitting model formula: z_Age ~ z_t_6 #>  #> 7: fitting model formula: z_Age ~ z_t_7 #>  #> 8: fitting model formula: z_Age ~ z_t_8 #>  #> 9: fitting model formula: z_Age ~ z_t_9 #>  #> 10: fitting model formula: z_Age ~ z_t_10 #>  #> 11: fitting model formula: z_Age ~ z_t_11 #>  #> 12: fitting model formula: z_Age ~ z_t_12 #>  #> 13: fitting model formula: z_Age ~ z_t_13 #>  #> 14: fitting model formula: z_Age ~ z_t_14 #>  #> 15: fitting model formula: z_Age ~ z_t_15 #>  #> 16: fitting model formula: z_Age ~ z_t_16 #>  #> 17: fitting model formula: z_Age ~ z_t_17 #>  #> 18: fitting model formula: z_Age ~ z_t_18 #>  #> 19: fitting model formula: z_Age ~ z_t_19 #>  #> 20: fitting model formula: z_Age ~ z_t_20 #>  #> The parameter y_variable is not set! Output 1 dimensional results. # }"},{"path":"https://r-topics.org/news/index.html","id":"topics-0402","dir":"Changelog","previous_headings":"","what":"topics 0.40.2","title":"topics 0.40.2","text":"changed behaviours topicsGrams(), including removing top_n treating n-grams type differently. added stopwords function topicsGrams(). fixed pmi calculation. fixed ngrams_max parameter `topicsPlot()```.","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-0401","dir":"Changelog","previous_headings":"","what":"topics 0.40.1","title":"topics 0.40.1","text":"adding allowed_word_overlap topicsPlot() plotting prevalence. improving help texts highlight_topic_words parameter add different colours word list. added stopwords removal topicsGram(). added ngrams_max functionality topicsPlot().","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-040","dir":"Changelog","previous_headings":"","what":"topics 0.40.","title":"topics 0.40.","text":"removing save_dir load_dir function; topicsPlot() now save_dir option. size dots distributions can plotted according prevalence. adding p_adjust_method topicsPlots().","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-0305","dir":"Changelog","previous_headings":"","what":"topics 0.30.5","title":"topics 0.30.5","text":"plots added list (saved folder) added scatter_show_axis_values topcisPlot(). adding feature plot n_most_prevalent_topics.","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-0304","dir":"Changelog","previous_headings":"","what":"topics 0.30.4","title":"topics 0.30.4","text":"scaling controls scale instead manually resulting slightly different estimates. (still p-value t-values) removed ridge regression, t-test correlation codes since work removed automatic removal NAs topics predictions (handled explicitly). topicsTest() default linear_regression variable contains 0s 1s; .e., now different tests can applied different axes.","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-0303","dir":"Changelog","previous_headings":"","what":"topics 0.30.3","title":"topics 0.30.3","text":"saving settings dtm downstream use functions. adding parameters topicsPred() function including num_iteration, sampling_interval, burn_in. implemented create_new_dtm creating new dtm new data adding test using topics dimension training using textTrainRegression(). removing forcing user set save_dir functions (need topics functions).","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-0302","dir":"Changelog","previous_headings":"","what":"topics 0.30.2","title":"topics 0.30.2","text":"fixing coherence bug showing prevalence coherence results restructuring files","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-0300","dir":"Changelog","previous_headings":"","what":"topics 0.30.0","title":"topics 0.30.0","text":"Harmonizing parameters topicsTest() incl. x_variable, y_variable controls fixing error variable names names 1 underscore.","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-0221","dir":"Changelog","previous_headings":"","what":"topics 0.22.1","title":"topics 0.22.1","text":"added pmi_threshold (experimental) topicsDtm() removed saving raw data split procedure topicsDtm() adding function name emphasized topics file name starts 0_. add parameter turn shuffling data topicsDtm()","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-022","dir":"Changelog","previous_headings":"","what":"topics 0.22","title":"topics 0.22","text":"change p_threshold p_alpha moved p_alpha topicsTest() function topicsPlots() function removed unnecessary list items topicsTest()","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-021","dir":"Changelog","previous_headings":"","what":"topics 0.21","title":"topics 0.21","text":"Changes related compatability text-package","code":""},{"path":"https://r-topics.org/news/index.html","id":"topics-020","dir":"Changelog","previous_headings":"","what":"topics 0.20","title":"topics 0.20","text":"Cleaning code ensuring improved compatibility across platforms. Started journey improving documentation.","code":""},{"path":[]},{"path":"https://r-topics.org/news/index.html","id":"change-0-10-1","dir":"Changelog","previous_headings":"","what":"Change","title":"topics 0.10.1","text":"Removing dim grid_plot arguments topicsPlot(). Fixing color bugs. Adding possibility user use gradient colors plots. Adding stop warning variable name contains underscore topicsTest().","code":""}]
